# mvp-medios  
### Monitoreo de medios con transcripciÃ³n por palabra, anÃ¡lisis narrativo y clipping exacto de audio

`mvp-medios` es un **MVP tÃ©cnico de monitoreo de medios** diseÃ±ado para procesar audio continuo (radio, TV, podcasts) y:

- Transcribir audio con **timestamp por palabra**
- Detectar **noticias completas** dentro de transmisiones largas
- Cortar audio de forma **exacta, reproducible y auditable**
- Generar **resÃºmenes confiables**, corregidos editorialmente

El sistema prioriza **coherencia narrativa** sobre pureza acÃºstica y estÃ¡ diseÃ±ado para escalar.

---

## ðŸŽ¯ Objetivo del proyecto

Resolver un problema clÃ¡sico del monitoreo de medios:

> *Â¿CÃ³mo identificar noticias reales dentro de audio continuo y cortarlas exactamente donde empiezan y terminan, sin perder contexto?*

Este proyecto responde a eso usando:
- **WhisperX** para tiempo real por palabra  
- **LLM** para anÃ¡lisis narrativo (no para tiempo)  
- **Reglas determinÃ­sticas** para decisiones finales  
- **Diccionario controlado** para correcciÃ³n de nombres  

---

## ðŸ§  Principios de diseÃ±o (no negociables)

Estas reglas gobiernan todo el sistema:

1. **La palabra es la unidad mÃ­nima de verdad**
2. **WhisperX es la Ãºnica fuente de tiempo**
3. **El LLM entiende narrativa, no segundos**
4. **El LLM propone, el sistema decide**
5. **No existe lag artificial**
6. **No existe solape entre chunks**
7. **El audio nunca se corta antes del anÃ¡lisis**
8. **La historia es mÃ¡s importante que la pureza del audio**
9. **El diccionario solo corrige, nunca enriquece**

---

## ðŸ” Flujo del sistema

1. **Audio crudo** 
2. **TranscripciÃ³n** (WhisperX, palabra por palabra)  
3. **Chunks de palabras** (texto, sin timestamps)  
4. **AnÃ¡lisis narrativo con LLM** 
5. **Reglas automÃ¡ticas del sistema** 
6. **Mapeo palabra â†’ tiempo real** 
7. **Clipping exacto de audio** 
8. **Resumen final corregido** 
---

## ðŸ“ Estructura del proyecto

```text
mvp-medios/
â”‚
â”œâ”€â”€ transcribe_audio.py
â”œâ”€â”€ chunk_words.py
â”œâ”€â”€ analyze_narrative_llm.py
â”œâ”€â”€ apply_rules.py
â”œâ”€â”€ map_words_to_time.py
â”œâ”€â”€ clip_audio.py
â”œâ”€â”€ summarize_news.py
â”‚
â”œâ”€â”€ correct_entities.py
â”œâ”€â”€ dictionary.json
â”‚
â”œâ”€â”€ input_audio/
â”œâ”€â”€ output_clips/
â”œâ”€â”€ temp/
â”‚
â””â”€â”€ README.md
```

**Cada archivo tiene una sola responsabilidad clara.**

ðŸŸ¦ 1. TranscripciÃ³n de audio
----------------------------

### transcribe\_audio.py

**Responsabilidad:** Convertir audio continuo en una lista ordenada de palabras con timestamps.**Entrada:** Archivo de audio (radio, TV, podcast)**Salida (Ejemplo):**

JSON
**Salida**
```json
[
  { "index": 0, "word": "buenos", "start": 0.52, "end": 0.71 },
  { "index": 1, "word": "dÃ­as", "start": 0.72, "end": 0.93 }
]
```

**Reglas clave:**

*   Timestamp por palabra.
    
*   Output inmutable.
    
*   WhisperX es la verdad absoluta temporal.
    

ðŸŸ¨ 2. Chunking por palabras (NO audio)
--------------------------------------

### chunk\_words.py

**Responsabilidad:** Dividir la transcripciÃ³n en grupos secuenciales de palabras para el anÃ¡lisis narrativo.**QuÃ© es un chunk:** Un rango de Ã­ndices de palabras, no segundos ni audio.

**Ejemplo:** Chunk 1 -> palabras 0-499 | Chunk 2 -> palabras 500-999**Reglas:** Sin solape, sin timestamps, solo Ã­ndice + palabra.

ðŸŸ§ 3. AnÃ¡lisis narrativo con LLM
--------------------------------

### analyze\_narrative\_llm.py

**Rol del LLM:** Identificar dÃ³nde empieza y termina cada noticia a nivel narrativo y generar un resumen inicial.**Salida del LLM (Ejemplo):**

JSON
```
[    {      "start_word": 320,      "end_word": 498,      "summary": "Nasri criticÃ³ al CNE por el proceso electoral."    }  ]   `
```
**Restricciones:** El LLM entiende historias, no tiempo. No produce timestamps ni decide duraciÃ³n.

âš™ï¸ 4. Decisiones automÃ¡ticas del sistema
----------------------------------------

### apply\_rules.py

**Responsabilidad:** Convertir propuestas del LLM en decisiones finales mediante lÃ³gica de negocio.**Reglas:** DuraciÃ³n mÃ­nima/mÃ¡xima, continuidad entre chunks, marcadores explÃ­citos.**El LLM propone. El sistema decide.**

ðŸŸ¦ 5. Mapeo de palabras a tiempo real
-------------------------------------

### map\_words\_to\_time.py

**Responsabilidad:** Traducir Ã­ndices de palabras a segundos reales usando la data inmutable de WhisperX.**Proceso:** start\_time = words\[start\_word\].start | end\_time = words\[end\_word\].end**Nota:** Paso determinista, reproducible y auditable.

ðŸŸ¥ 6. Clipping de audio
-----------------------

### clip\_audio.py

**Responsabilidad:** Cortar audio exactamente donde el sistema lo indica usando FFmpeg. No analiza texto, solo ejecuta cortes tÃ©cnicos.

ðŸŸª 7. Resumen final y correcciÃ³n editorial
------------------------------------------

### summarize\_news.py / correct\_entities.py

**Responsabilidad:** Entregar el resumen final para consumo humano usando dictionary.json.**Reglas estrictas:**

*   âœ… Corregir errores ortogrÃ¡ficos de nombres propios.
    
*   âœ… Normalizar variantes conocidas.
    
*   âŒ No expande nombres ni introduce informaciÃ³n nueva.
    

ðŸ§  Manejo de mÃºltiples periodistas
----------------------------------

*   Se aceptan interrupciones y solapamientos.
    
*   El speaker NO define cortes. El tema manda.
    
*   La historia es mÃ¡s importante que la pureza del audio.
    

ðŸ“¤ Output final
---------------

Por cada noticia detectada: Clip exacto de audio, Resumen corregido, Inicio y fin reales (segundos) y Texto legible.

ðŸ§ª Estado del proyecto
----------------------

Este repositorio define un MVP tÃ©cnico sÃ³lido: escalable, auditable, determinista y mantenible.

> **"El LLM entiende historias. WhisperX entiende tiempo. El sistema conecta ambos."**



